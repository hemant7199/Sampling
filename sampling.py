# -*- coding: utf-8 -*-
"""Sampling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VR01ubbS6yGj8lBOfJ93cXI8BED5cc7U
"""

import numpy as np
import pandas as pd
from sklearn import datasets

rdf = pd.read_csv('./Creditcard_data.csv')
print(rdf.shape)
rdf.head()

rdf["Class"].unique()

rdf.describe()

fraud_df = rdf[rdf["Class"] == 1]
fair_df  = rdf[rdf["Class"] == 0]
print(fraud_df.shape)
print(fair_df.shape)

print(rdf["Class"].value_counts())

rdf.groupby('Class').size().plot(kind='pie', y = "Class", label = "Type", autopct='%1.1f%%')

x = rdf.drop("Class", axis=1)
y = rdf[['Class']]

from imblearn.over_sampling import SMOTE

su = SMOTE(random_state=42)
X_su, Y_su = su.fit_resample(x, y)

print(Y_su["Class"].value_counts())

Y_su.groupby('Class').size().plot(kind='pie', y = "Class", label = "Type", autopct='%1.1f%%')

df = pd.DataFrame(X_su)
df['Class'] = Y_su
print(df.shape)
df.head()

from sklearn.preprocessing import RobustScaler
scaler = RobustScaler().fit(df[["Time", "Amount"]])
df[["Time", "Amount"]] = scaler.transform(df[["Time", "Amount"]])

df.head()

df.describe()

random_df = df.sample(n=382, random_state=42)
print(random_df.shape)
random_df.head()

random_Y_train = random_df["Class"]
random_X_train = random_df.iloc[:,0:30]

indexes = np.arange(0, len(df), step=4)
systematic_df = df.iloc[indexes]
print(systematic_df.shape)
systematic_df.head()

systematic_Y_train = systematic_df["Class"]
systematic_X_train = systematic_df.iloc[:,0:30]

low_percentile = np.percentile(df['Amount'], 25)
normal_percentile = np.percentile(df['Amount'], 75)

AmountGroup = []
for row in df['Amount']:
    if row <= low_percentile :    AmountGroup.append(0)
    elif row > low_percentile and row < normal_percentile :   AmountGroup.append(1)
    elif row >= normal_percentile :  AmountGroup.append(2)

df['AmountGroup'] = AmountGroup
df.head()

stratified_df = df.groupby('AmountGroup', group_keys=False).apply(lambda x: x.sample(frac=0.25))
print(stratified_df.shape)
stratified_df.head()

stratified_Y_train = stratified_df["Class"]
stratified_X_train = stratified_df.iloc[:,0:30]

def clustered_Sample(df, rows_per_cluster, no_of_clusters):
    K = int(len(df)/rows_per_cluster)
    cl_data = None
    for k in range(K):
        sample_cl = df.sample(rows_per_cluster)
        sample_cl["Cluster"] = np.repeat(k,len(sample_cl))
        df = df.drop(index = sample_cl.index)
        cl_data = pd.concat([cl_data,sample_cl],axis = 0)

    random_clusters = np.random.randint(0,K,size = no_of_clusters)
    samples = cl_data[cl_data.Cluster.isin(random_clusters)]
    return(samples)

clustered_df = clustered_Sample(df = df, rows_per_cluster = 96, no_of_clusters = 4)
print(clustered_df.shape)
clustered_df.head()

clustered_Y_train = clustered_df["Class"]
clustered_X_train = clustered_df.iloc[:,0:30]

df['weights'] = df['AmountGroup'].map({0: 20, 1: 60, 2: 20})
weighted_df = df.sample(n=382, weights='weights')
print(weighted_df.shape)
weighted_df.head()

weighted_Y_train = weighted_df["Class"]
weighted_X_train = weighted_df.iloc[:,0:30]

models = {}

# Logistic Regression
from sklearn.linear_model import LogisticRegression
models['Logistic Regression'] = LogisticRegression()

# Decision Trees
from sklearn.tree import DecisionTreeClassifier
models['Decision Trees'] = DecisionTreeClassifier()

# Random Forest
from sklearn.ensemble import RandomForestClassifier
models['Random Forest'] = RandomForestClassifier()

# Naive Bayes
from sklearn.naive_bayes import GaussianNB
models['Naive Bayes'] = GaussianNB()

# K-Nearest Neighbors
from sklearn.neighbors import KNeighborsClassifier
models['K-Nearest Neighbor'] = KNeighborsClassifier()

from sklearn.metrics import accuracy_score, precision_score, recall_score

X_test = df.iloc[:,0:30]
Y_test = Y_su

random_accuracy, random_precision, random_recall = {}, {}, {}

for key in models.keys():

    # Fit the classifier
    models[key].fit(random_X_train, random_Y_train)

    # Make predictions
    random_predictions = models[key].predict(X_test)

    # Calculate evaluation metrics

    random_accuracy[key] = accuracy_score(random_predictions, Y_test)
    random_precision[key] = precision_score(random_predictions, Y_test)
    random_recall[key] = recall_score(random_predictions, Y_test)

systematic_accuracy, systematic_precision, systematic_recall = {}, {}, {}

for key in models.keys():

    # Fit the classifier
    models[key].fit(systematic_X_train, systematic_Y_train)

    # Make predictions
    systematic_predictions = models[key].predict(X_test)

    # Calculate evaluation metrics
    systematic_accuracy[key] = accuracy_score(systematic_predictions, Y_test)
    systematic_precision[key] = precision_score(systematic_predictions, Y_test)
    systematic_recall[key] = recall_score(systematic_predictions, Y_test)

stratified_accuracy, stratified_precision, stratified_recall = {}, {}, {}

for key in models.keys():

    # Fit the classifier
    models[key].fit(stratified_X_train, stratified_Y_train)

    # Make predictions
    stratified_predictions = models[key].predict(X_test)

    # Calculate evaluation metrics
    stratified_accuracy[key] = accuracy_score(stratified_predictions, Y_test)
    stratified_precision[key] = precision_score(stratified_predictions, Y_test)
    stratified_recall[key] = recall_score(stratified_predictions, Y_test)

clustered_accuracy, clustered_precision, clustered_recall = {}, {}, {}

for key in models.keys():

    # Fit the classifier
    models[key].fit(clustered_X_train, clustered_Y_train)

    # Make predictions
    clustered_predictions = models[key].predict(X_test)

    # Calculate evaluation metrics
    clustered_accuracy[key] = accuracy_score(clustered_predictions, Y_test)
    clustered_precision[key] = precision_score(clustered_predictions, Y_test)
    clustered_recall[key] = recall_score(clustered_predictions, Y_test)

weighted_accuracy, weighted_precision, weighted_recall = {}, {}, {}

for key in models.keys():

    # Fit the classifier
    models[key].fit(weighted_X_train, weighted_Y_train)

    # Make predictions
    weighted_predictions = models[key].predict(X_test)

    # Calculate evaluation metrics
    weighted_accuracy[key] = accuracy_score(weighted_predictions, Y_test)
    weighted_precision[key] = precision_score(weighted_predictions, Y_test)
    weighted_recall[key] = recall_score(weighted_predictions, Y_test)

accuracy_table = pd.DataFrame()
accuracy_table['Random Sampling'] = random_accuracy
accuracy_table['Systematic Sampling'] = systematic_accuracy
accuracy_table['Stratified Sampling'] = stratified_accuracy
accuracy_table['Clustered Sampling'] = clustered_accuracy
accuracy_table['Weighted Sampling'] = weighted_accuracy

accuracy_table